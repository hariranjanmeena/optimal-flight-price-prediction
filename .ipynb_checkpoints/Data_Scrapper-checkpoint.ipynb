{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddca5df3",
   "metadata": {},
   "source": [
    "# Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c3245a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required module imports\n",
    "import sys\n",
    "import csv\n",
    "from time import sleep, strftime\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c8f577",
   "metadata": {},
   "source": [
    "# Creating  list of dates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b370a66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "dates = []\n",
    "start = datetime.datetime.strptime(\"01-01-2022\", \"%d-%m-%Y\")\n",
    "end = datetime.datetime.strptime(\"01-07-2022\", \"%d-%m-%Y\")\n",
    "date_generated = [start + datetime.timedelta(days=x) for x in range(0, (end-start).days)]\n",
    "\n",
    "for date in date_generated:\n",
    "    dates.append(str(date.strftime(\"%Y-%m-%d\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8649a626",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_data = []\n",
    "for i,j in zip(date_generated,dates):\n",
    "    date_data.append([i,j])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b6395c",
   "metadata": {},
   "source": [
    "# Choose city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc5f4997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User defined variables for data retreival\n",
    "city_from = \"jaipur\"             # Origin airport code\n",
    "city_to = \"new delhi\" # Destination airport code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f234025a",
   "metadata": {},
   "source": [
    "# code to scrap data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d41ac1df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting URL: https://www.kayak.co.in/flights/jaipur-new delhi/2022-01-01?sort=price_a\n",
      "Webpage found ...\n",
      "show all results.....\n",
      "done.....\n",
      "load more results.....\n",
      "Getting data from DOM ...\n",
      "Writing flight data to file: FlightsData_jaipur-new delhi-2022-01-01.csv ...\n",
      "Closing Chrome ...\n",
      "Requesting URL: https://www.kayak.co.in/flights/jaipur-new delhi/2022-01-02?sort=price_a\n",
      "Webpage found ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-7113c78c9bcf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbaseDataUrl\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# URL requested in browser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"Webpage found ...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for t in range(len(date_data)):\n",
    "    \n",
    "    # url to display data\n",
    "    baseDataUrl =     kayak = ('https://www.kayak.co.in/flights/' + city_from + '-' + city_to +'/' + date_data[t][1] + '?sort=price_a')\n",
    "\n",
    "\n",
    "    # webdriver.Chrome(ChromeDriverManager().install())\n",
    "    driver = webdriver.Chrome(executable_path=\"chromedriver.exe\") # Chrome driver is being used.\n",
    "\n",
    "    print (\"Requesting URL: \" + baseDataUrl)\n",
    "\n",
    "    driver.get(baseDataUrl)   # URL requested in browser.\n",
    "    print (\"Webpage found ...\")\n",
    "    sleep(20)\n",
    "\n",
    "    try:\n",
    "        xp_popup_close = '//button[contains(@id,\"-dialog-close\") and contains(@class,\"Button-No-Standard-Style close inside darkIcon \")]'\n",
    "        l = len(driver.find_elements_by_xpath(xp_popup_close))\n",
    "        driver.find_elements_by_xpath(xp_popup_close)[l-1].click()\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "    element_xpath = '//div[contains(@class,\"Base-Results-ResultsPage Flights-Results-FlightResultsPage ResultsVisible PhoenixRising narrow-padding\")]' # First box with relevant flight data.\n",
    "\n",
    "    # Wait until the first box with relevant flight data appears on Screen\n",
    "    element = WebDriverWait(driver, 15).until(EC.visibility_of_element_located((By.XPATH, element_xpath)))\n",
    "    sleep(10)\n",
    "\n",
    "    try:\n",
    "        print('show all results.....')\n",
    "        show_all = '//a[@class=\"showAll\"]'\n",
    "        driver.find_element_by_xpath(show_all).click()\n",
    "        print('done.....')\n",
    "        sleep(15)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    #   click on show more \n",
    "    try:\n",
    "        print('load more results.....')\n",
    "        load_more = '//div[@class=\"resultsPaginator\"]'\n",
    "        driver.find_element_by_xpath(show_all).click()\n",
    "        print('done.....')\n",
    "        sleep(10)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Find the document body and get its inner HTML for processing in BeautifulSoup parser.\n",
    "    body = driver.find_element_by_tag_name(\"body\").get_attribute(\"innerHTML\")\n",
    "\n",
    "    print(\"Getting data from DOM ...\")\n",
    "    soupBody = BeautifulSoup(body,'html') # Parse the inner HTML using BeautifulSoup\n",
    "\n",
    "    airline = soupBody.find_all(\"span\", \"codeshares-airline-names\") \n",
    "    date_list = date_data[t][0].day\n",
    "    weekday = date_data[t][0].weekday()\n",
    "    month = date_data[t][0].month\n",
    "    year = date_data[t][0].year\n",
    "    depr_time = soupBody.find_all(\"span\", \"depart-time base-time\")  \n",
    "    ar_time = soupBody.find_all(\"span\", \"arrival-time base-time\") \n",
    "    depr_city_name = 'jaipur'   \n",
    "\n",
    "    ar_city_name = city_to \n",
    "    travel_time = soupBody.find_all(\"div\", \"section duration allow-multi-modal-icons\")    \n",
    "    airline_cabin = 'E'\n",
    "    no_of_stops =soupBody.find_all(\"span\", \"stops-text\")   \n",
    "    prices_list = soupBody.find_all(\"span\", \"price option-text\")  \n",
    "    \n",
    "    # Fixing price\n",
    "    price = []\n",
    "    for i in range(len(prices_list)):\n",
    "        p = prices_list[i].text\n",
    "        p = p.strip().replace(',','')[2:]\n",
    "        price.append(p)\n",
    "\n",
    "    flightsData = []\n",
    "    flight_details = [\"airlines\" ,\"Date\", \"Month\", \"Year\",\"Weekday\", \"Dep_Time\",\"Ar_Time\", \"depr_Citie\", \"Ar_Citie\", \"Travel_Time\", \"Airline_Cabin\", \"no_stops\",  \"Price\"]\n",
    "\n",
    "    # Extracting data from tags and appending to main database flightsData\n",
    "    for i in range(0, len(airline)):\n",
    "        flightsData.append([airline[i].text, date_list, month, year, weekday, depr_time[i].text, ar_time[i].text , depr_city_name , ar_city_name, travel_time[i].find('div','top').text.strip() , airline_cabin, no_of_stops[i].text.strip(), price[i] ] )\n",
    "\n",
    "    flight_Df = pd.DataFrame(flightsData,columns=flight_details)\n",
    "\n",
    "    flight_Df['timestamp'] = strftime(\"%Y%m%d-%H%M\") # so we can know when it was scraped\n",
    "\n",
    "    outputFile = \"FlightsData_\" + city_from +\"-\"+ city_to +\"-\"+ date_data[t][1] + \".csv\"\n",
    "    \n",
    "    print(\"Writing flight data to file: \"+ outputFile + \" ...\")\n",
    "    flight_Df.to_csv(\"flight_data\\\\\"+outputFile,index=False)\n",
    "    \n",
    "    print(\"Closing Chrome ...\") # No more usage needed.\n",
    "    driver.quit() # Browser Closed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb65e73f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5426d930",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
